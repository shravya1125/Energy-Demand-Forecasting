{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI-Powered Energy Demand Forecasting\n",
        "\n",
        "**Notebook:** `energy_demand_forecasting_notebook.ipynb`\n",
        "\n",
        "Author: Your Name  \n",
        "Internship ID: INTERNSHIP_17513641056863b20937d78  \n",
        "Theme: Sustainable Energy & Efficiency\n",
        "\n",
        "----\n",
        "**Notes before running:**\n",
        "- This notebook first tries to load a CSV file `./data/energy_consumption.csv` (you can put your dataset there).  \n",
        "- If that file is not found, the notebook generates a synthetic hourly dataset (1 year) so you can run end-to-end immediately.  \n",
        "- Replace the synthetic data with your real dataset and adjust column names if needed.  \n",
        "- Keep the final `.ipynb` size < 10MB \u2014 remove large saved models or heavy logs before submission.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Imports & Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import joblib\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    denom = np.where(y_true==0, 1e-6, y_true)\n",
        "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Load dataset or generate synthetic data\n",
        "\n",
        "Place your CSV at `./data/energy_consumption.csv`. Expected columns (if you use your own data):\n",
        "- `timestamp` (datetime-like)  \n",
        "- `energy` or `load` (target variable: energy demand)  \n",
        "- Optional weather features: `temperature`, `humidity`, `wind_speed`, `solar_radiation`\n",
        "\n",
        "If the file is not found, synthetic hourly data for 1 year will be generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Try to load local dataset\n",
        "DATA_PATH = './data/energy_consumption.csv'\n",
        "if os.path.exists(DATA_PATH):\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print('Loaded dataset from', DATA_PATH)\n",
        "else:\n",
        "    # Generate synthetic hourly data for 1 year\n",
        "    print('No local dataset found. Generating synthetic hourly data for 1 year...')\n",
        "    rng = pd.date_range(start='2023-01-01', periods=24*365, freq='H')\n",
        "    np.random.seed(42)\n",
        "    base = 200 + 40*np.sin(2 * np.pi * (rng.hour) / 24)  # daily seasonality\n",
        "    seasonal = 20*np.sin(2 * np.pi * (rng.dayofyear) / 365)  # yearly seasonality\n",
        "    noise = np.random.normal(0, 8, len(rng))\n",
        "    temperature = 20 + 10*np.sin(2 * np.pi * (rng.dayofyear) / 365) + np.random.normal(0,2,len(rng))\n",
        "    humidity = 60 + 10*np.cos(2 * np.pi * (rng.hour) / 24) + np.random.normal(0,3,len(rng))\n",
        "    energy = base + seasonal - 0.8*temperature + 0.3*humidity + noise\n",
        "    df = pd.DataFrame({\n",
        "        'timestamp': rng,\n",
        "        'energy': energy,\n",
        "        'temperature': temperature,\n",
        "        'humidity': humidity\n",
        "    })\n",
        "    os.makedirs('./data', exist_ok=True)\n",
        "    df.to_csv(DATA_PATH, index=False)\n",
        "    print('Synthetic dataset saved to', DATA_PATH)\n",
        "\n",
        "# Quick check\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df = df.sort_values('timestamp').reset_index(drop=True)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Exploratory Data Analysis (EDA)\n",
        "Plot the time series and look at statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('Dataset length:', len(df))\n",
        "print(df[['energy','temperature','humidity']].describe().T)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(df['timestamp'][:24*14], df['energy'][:24*14])\n",
        "plt.title('Energy demand (first 14 days)')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Energy')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Daily aggregation sample\n",
        "df_daily = df.set_index('timestamp').resample('D').mean().reset_index()\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(df_daily['timestamp'][:90], df_daily['energy'][:90])\n",
        "plt.title('Daily average energy (first 90 days)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Energy')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Feature Engineering\n",
        "- Create lag features (previous 1, 24, 168 hours)\n",
        "- Time features: hour, dayofweek, month\n",
        "- Optionally rolling means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_fe = df.copy()\n",
        "df_fe['hour'] = df_fe['timestamp'].dt.hour\n",
        "df_fe['dayofweek'] = df_fe['timestamp'].dt.dayofweek\n",
        "df_fe['month'] = df_fe['timestamp'].dt.month\n",
        "\n",
        "# Lag features\n",
        "for lag in [1, 24, 168]:\n",
        "    df_fe[f'lag_{lag}'] = df_fe['energy'].shift(lag)\n",
        "\n",
        "# Rolling means\n",
        "df_fe['rmean_24'] = df_fe['energy'].rolling(window=24).mean().shift(1)\n",
        "df_fe['rmean_168'] = df_fe['energy'].rolling(window=168).mean().shift(1)\n",
        "\n",
        "df_fe = df_fe.dropna().reset_index(drop=True)\n",
        "print('After feature engineering length:', len(df_fe))\n",
        "df_fe.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Train/test split\n",
        "We will do a time-based split (no shuffling). Use the last 20% as test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_size = int(0.8 * len(df_fe))\n",
        "train = df_fe.iloc[:train_size].copy()\n",
        "test = df_fe.iloc[train_size:].copy()\n",
        "\n",
        "features = ['lag_1','lag_24','lag_168','rmean_24','rmean_168','hour','dayofweek','month','temperature','humidity']\n",
        "target = 'energy'\n",
        "\n",
        "X_train = train[features].values\n",
        "y_train = train[target].values\n",
        "X_test = test[features].values\n",
        "y_test = test[target].values\n",
        "\n",
        "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Baseline Models: Linear Regression and Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Scale features for Linear Regression\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Linear Regression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "pred_lr = lr.predict(X_test_scaled)\n",
        "print('Linear Regression RMSE:', rmse(y_test, pred_lr))\n",
        "print('Linear Regression MAPE:', mape(y_test, pred_lr))\n",
        "\n",
        "# Random Forest (no scaling needed)\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "pred_rf = rf.predict(X_test)\n",
        "print('Random Forest RMSE:', rmse(y_test, pred_rf))\n",
        "print('Random Forest MAPE:', mape(y_test, pred_rf))\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(test['timestamp'].values, y_test, label='Actual')\n",
        "plt.plot(test['timestamp'].values, pred_rf, label='RF Predicted')\n",
        "plt.legend()\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Energy')\n",
        "plt.title('Actual vs RF Predicted (Test set)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Advanced Model: LSTM (sequence-to-one forecasting)\n",
        "\n",
        "We will create sequences using previous `seq_hours` hours to predict the next hour.\n",
        "This section requires `tensorflow`/`keras`. If your environment doesn't have tensorflow, you can skip LSTM and rely on RandomForest / XGBoost.\n",
        "If tensorflow is not installed, run `pip install tensorflow` in your environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# LSTM modeling (make this optional depending on environment)\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "    print('TensorFlow version:', tf.__version__)\n",
        "    TF_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    print('TensorFlow not available in this environment. Skipping LSTM. Error:', e)\n",
        "    TF_AVAILABLE = False\n",
        "\n",
        "if TF_AVAILABLE:\n",
        "    seq_hours = 48\n",
        "    def create_sequences(X, y, seq_len=seq_hours):\n",
        "        Xs, ys = [], []\n",
        "        for i in range(seq_len, len(X)):\n",
        "            Xs.append(X[i-seq_len:i])\n",
        "            ys.append(y[i])\n",
        "        return np.array(Xs), np.array(ys)\n",
        "\n",
        "    # We'll use scaled features for LSTM\n",
        "    X_all = np.vstack([X_train_scaled, X_test_scaled])\n",
        "    y_all = np.hstack([y_train, y_test])\n",
        "    # Create sequences on full dataset then split by index\n",
        "    X_seq, y_seq = create_sequences(X_all, y_all, seq_len=seq_hours)\n",
        "    split_index = int(0.8 * len(X_seq))\n",
        "    X_seq_train, X_seq_test = X_seq[:split_index], X_seq[split_index:]\n",
        "    y_seq_train, y_seq_test = y_seq[:split_index], y_seq[split_index:]\n",
        "    print('LSTM input shapes:', X_seq_train.shape, X_seq_test.shape)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=(X_seq_train.shape[1], X_seq_train.shape[2]), return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    \n",
        "    # Train\n",
        "    history = model.fit(X_seq_train, y_seq_train, epochs=10, batch_size=64, validation_data=(X_seq_test, y_seq_test))\n",
        "\n",
        "    # Predict\n",
        "    pred_lstm = model.predict(X_seq_test).flatten()\n",
        "    print('LSTM RMSE:', rmse(y_seq_test, pred_lstm))\n",
        "    print('LSTM MAPE:', mape(y_seq_test, pred_lstm))\n",
        "\n",
        "    # Plot training loss\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(history.history['loss'], label='train_loss')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss')\n",
        "    plt.title('LSTM Training Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "else:\n",
        "    print('LSTM section skipped. Install tensorflow to run this cell.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Save best model & artifacts\n",
        "Save scaler and Random Forest (or best model). For submission keep model files out of the notebook (or compress) to stay under 10 MB.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save scaler and RF model to disk\n",
        "os.makedirs('./artifacts', exist_ok=True)\n",
        "joblib.dump(scaler, './artifacts/scaler.joblib')\n",
        "joblib.dump(rf, './artifacts/random_forest.joblib')\n",
        "print('Saved scaler and Random Forest to ./artifacts')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Conclusion & How to Replace with Your Real Dataset\n",
        "\n",
        "1. Replace `./data/energy_consumption.csv` with your file and rerun the notebook.  \n",
        "2. Ensure your datetime column is called `timestamp` (or adjust the code).  \n",
        "3. Make sure `energy` is the target column name or change `target = 'energy'`.  \n",
        "4. If using a large dataset, consider downsampling or using a sample for the notebook to keep <10MB.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "End of notebook. Replace author details and add your README in the repo.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}